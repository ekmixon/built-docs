<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="An explanation of how the data frame analytics jobs work. Every job has four or five main phases depending on its analysis type.">
<meta name="keywords" content="ML, Elastic Stack, data frame analytics, advanced,">
<title>Evaluating data frame analytics | Machine Learning in the Elastic Stack [master] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [master]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Advanced concepts"/>
<link rel="prev" href="ml-inference.html" title="Inference"/>
<link rel="next" href="ml-feature-encoding.html" title="Feature encoding"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/master"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="master"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [master]</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Advanced concepts</a></span>
»
<span class="breadcrumb-node">Evaluating data frame analytics</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-inference.html">« Inference</a>
</span>
<span class="next">
<a href="ml-feature-encoding.html">Feature encoding »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-dfanalytics-evaluate"></a>Evaluating data frame analytics<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-dfanalytics-regression-evaluation"></a>Regression evaluation<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h3>
</div></div></div>
<p>This evaluation type is suitable for evaluating regression models. The
regression evaluation type offers the following metrics to evaluate the model
performance:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Mean squared error (MSE)
</li>
<li class="listitem">
R-squared (R<sup>2</sup>)
</li>
<li class="listitem">
Pseudo-Huber loss
</li>
<li class="listitem">
Mean squared logarithmic error (MSLE)
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-mse"></a>Mean squared error<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p>The API provides a MSE by computing the average squared sum of the difference
between the true value and the value that the regression model predicted.
(Avg (predicted value-actual value)<sup>2</sup>). You can use the MSE to measure how well
the regression analysis model is performing.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-r-sqared"></a>R-squared<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p>Another evaluation metric for regression analysis is R-squared (R<sup>2</sup>). It represents
the goodness of fit and measures how much of the variation in the data the
predictions are able to explain. The value of R<sup>2</sup> are less than or equal to 1,
where 1 indicates that the predictions and true values are equal. A value of 0
is obtained when all the predictions are set to the mean of the true values. A
value of 0.5 for R<sup>2</sup> would indicate that, the predictions are 1 - 0.5<sup>(1/2)</sup>
(about 30%) closer to true values than their mean.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-huber"></a>Pseudo-Huber loss<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p><a href="https://en.wikipedia.org/wiki/Huber_loss#Pseudo-Huber_loss_function" class="ulink" target="_top">Pseudo-Huber loss metric</a>
behaves as mean absolute error (MAE) for errors larger than a predefined value
(defaults to <code class="literal">1</code>) and as mean squared error (MSE) for errors smaller than the
predefined value. This loss function uses the <code class="literal">delta</code> parameter to define the
transition point between MAE and MSE. Consult the
<a class="xref" href="dfa-regression.html#dfa-regression-lossfunction" title="Loss functions for regression analyses">Loss functions for regression analyses</a> page to learn more about loss functions.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-msle"></a>Mean squared logarithmic error<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p>This evaluation metric is a variation of mean squared error. It can be used for
cases when the target values are positive and distributed with a long tail such
as data on prices or population. Consult the <a class="xref" href="dfa-regression.html#dfa-regression-lossfunction" title="Loss functions for regression analyses">Loss functions for regression analyses</a>
page to learn more about loss functions.</p>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-dfanalytics-classification"></a>Classification evaluation<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h3>
</div></div></div>
<p>This evaluation type is suitable for evaluating classification models. The
classification evaluation offers the following metrics to evaluate the model
performance:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Multiclass confusion matrix
</li>
<li class="listitem">
Area under the curve of receiver operating characteristic (AUC ROC)
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-mccm"></a>Multiclass confusion matrix<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p>The multiclass confusion matrix provides a summary of the performance of the
classification analysis. It contains the number of occurrences where the analysis
classified data points correctly with their actual class as well as the number
of occurrences where it misclassified them.</p>
<p>Let&#8217;s see two examples of the confusion matrix. The first is a confusion matrix
of a binary problem:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/confusion-matrix-binary.jpg" alt="Confusion matrix of a binary problem" width="75%">
</div>
</div>
<p>It is a two by two matrix because there are only two classes (<code class="literal">true</code> and
<code class="literal">false</code>). The matrix shows the proportion of data points that is correctly
identified as members of a each class and the proportion that is
misidentified.</p>
<p>As the number of classes in your classification analysis increases, the confusion
matrix also increases in complexity:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/confusion-matrix-multiclass.jpg" alt="Confusion matrix of a multiclass problem" width="100%">
</div>
</div>
<p>The matrix contains the actual labels on the left side while the predicted
labels are on the top. The proportion of correct and incorrect predictions is
broken down for each class. This enables you to examine how the classification analysis
confused the different classes while it made its predictions.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-dfanalytics-class-aucroc"></a>Area under the curve of receiver operating characteristic (AUC ROC)<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/master/docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc">edit</a></h4>
</div></div></div>
<p>The receiver operating characteristic (ROC) curve is a plot that represents the
performance of the classification process at different predicted probability
thresholds. It compares the true positive rate for a specific class against the
rate of all the other classes combined ("one versus all" strategy) at the
different threshold levels to create the curve.</p>
<p>Let&#8217;s see an example. You have three classes: <code class="literal">A</code>, <code class="literal">B</code>, and <code class="literal">C</code>, you want to
calculate AUC ROC for <code class="literal">A</code>. In this case, the number of correctly classified
<code class="literal">A</code>s (true positives) are compared to the number of <code class="literal">B</code>s and <code class="literal">C</code>s that are
misclassified as <code class="literal">A</code>s (false positives).</p>
<p>From this plot, you can compute the area under the curve (AUC) value, which is a
number between 0 and 1. The higher the AUC, the better the model is at
predicting <code class="literal">A</code>s as <code class="literal">A</code>s, in this case.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>To use this evaluation method, you must set <code class="literal">num_top_classes</code> to <code class="literal">-1</code>
or a value greater than or equal to the total number of classes when you create
the data frame analytics job.</p>
</div>
</div>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="ml-inference.html">« Inference</a>
</span>
<span class="next">
<a href="ml-feature-encoding.html">Feature encoding »</a>
</span>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>
